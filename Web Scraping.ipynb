{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93c8352",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c15e9b",
   "metadata": {},
   "source": [
    "* A **Website** is a collection of related web pages that may contain text, images, audio and video. It can be static or dynamic.\n",
    "\n",
    "\n",
    "* **HTTP** is the data communication protocol used to establish communication between client and server.\n",
    "\n",
    "\n",
    "* **HTTP Requests**\tis the request send by the computer to a web server that contains all sorts of potentially interesting information.\n",
    "\n",
    "\n",
    "* A **Server** is used to manage the network resources (**web server**). Servers are also used for running the program or software that provides services (**application server**).\n",
    "\n",
    "\n",
    "* **API** or **Application Programming Interface** allows interactions between systems by following a set of standards and protocols in order to share features, information and data. API acts as an interface between different applications.\n",
    "\n",
    "\n",
    "* A **REST API** (or **Representational State Transfer API**) is an architecture style to develop web applications. It uses HTTP protocol as a communication inteface for different software systems to communicate with each other through the internet. It transfers data through HTTP methods. There are five main methods used in a REST API:\n",
    "\t* `GET` - retrieves a specific resource or collection of resources\n",
    "\t* `POST` - creates a new resource\n",
    "\t* `PUT` - updates an existing resource\n",
    "\t* `DELETE` - removes a specific resource\n",
    "\t* `PATCH` - partially updates an existing resource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0230114a",
   "metadata": {},
   "source": [
    "* **GET** request data from a resource (URL) whereas **POST** creates/updates a response.\n",
    "\t* `GET` : `requests.get(\"<url>\")`\n",
    "\t* `POST` : `requests.post(\"<url>\", data={\"key\":\"value\"})`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c6038",
   "metadata": {},
   "source": [
    "* The **Response** object is returned from the HTTP request that holds the results of the request, it can either be a success or an error. A success response typically includes the requested information or a message confirming that the requested action was completed. An error response includes a message explaining why the request could not be completed. The Response object contains not only the **page content**, but also many other items about the result such as **HTTP status codes** and **headers**.\n",
    "    * **Content Type** is HTTP header that provides the description about what are we sending to the browser.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97763e04",
   "metadata": {},
   "source": [
    "* Output for common requests attributes:\n",
    "\t* `response.content`: raw bytes response payload\n",
    "    * `response.text`: character encoded (e.g. UTF-8) string payload\n",
    "    * `response.headers`: dictionary-like object which contains header payload as key-value\n",
    "\t* `response.status_code`: status code returned by the external service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1474f4",
   "metadata": {},
   "source": [
    "* Requests is used only to get the page, it **does not do an parsing**.\n",
    "\n",
    "* We use **Beautiful Soup** to do the parsing of the HTML and also the finding of content within the HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb6d4d0",
   "metadata": {},
   "source": [
    "## Scrape the upcoming Python events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8944e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847d2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CSS classes from \"Right Click / Inspect\", and search the element\n",
    "css_class_dict = {'recent_events_class' : 'list-recent-events',\n",
    "                 'event_location_class' : 'event-location'}\n",
    "\n",
    "# URL for website\n",
    "url = 'https://www.python.org/events/python-events/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e6e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_response(response_text, css_class_dict):\n",
    "    \n",
    "    # create a BeautifulSoup object and pass it the HTML text\n",
    "    soup = BeautifulSoup(response_text, 'lxml')\n",
    "    \n",
    "    # find the main <ul> tag for the recent events, and then to get all the <li> tags below it\n",
    "    events = soup.find('ul', {'class': css_class_dict['recent_events_class']}).findAll('li')\n",
    "    \n",
    "    # mapping all results to upcoming_events\n",
    "    upcoming_events = []\n",
    "    for event in events:\n",
    "        event_details = dict()\n",
    "        event_details['name'] = event.find('h3').find(\"a\").text\n",
    "        event_details['location'] = event.find('span', {'class', css_class_dict['event_location_class']}).text\n",
    "        event_details['time'] = event.find('time').text\n",
    "        upcoming_events.append(event_details)\n",
    "\n",
    "    # Creating events dataframe\n",
    "    events_df = pd.DataFrame(upcoming_events)\n",
    "        \n",
    "    return events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15711f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upcoming_events(response_text, css_class_dict):\n",
    "    events_df = _parse_response(response_text, css_class_dict)\n",
    "    return events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09cb1fa",
   "metadata": {},
   "source": [
    "### Using `requests` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ab86a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57b59cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EuroPython 2023</td>\n",
       "      <td>Prague, Czech Republic</td>\n",
       "      <td>17 July – 23 July  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North Bay Python</td>\n",
       "      <td>Petaluma, California, USA</td>\n",
       "      <td>29 July – 30 July  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PyCon PL 2023</td>\n",
       "      <td>Gliwice, Poland</td>\n",
       "      <td>29 July – 02 Aug.  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PyCon KR</td>\n",
       "      <td>Seoul, South Korea</td>\n",
       "      <td>11 Aug. – 13 Aug.  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EuroSciPy 2023</td>\n",
       "      <td>Basel, Switzerland</td>\n",
       "      <td>14 Aug. – 18 Aug.  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DjangoConAU 2023</td>\n",
       "      <td>Adelaide, Australia</td>\n",
       "      <td>18 Aug. 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                   location                     time\n",
       "0   EuroPython 2023     Prague, Czech Republic  17 July – 23 July  2023\n",
       "1  North Bay Python  Petaluma, California, USA  29 July – 30 July  2023\n",
       "2     PyCon PL 2023            Gliwice, Poland  29 July – 02 Aug.  2023\n",
       "3          PyCon KR         Seoul, South Korea  11 Aug. – 13 Aug.  2023\n",
       "4    EuroSciPy 2023         Basel, Switzerland  14 Aug. – 18 Aug.  2023\n",
       "5  DjangoConAU 2023        Adelaide, Australia             18 Aug. 2023"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET HTTP request using requests library\n",
    "response = requests.get(url)\n",
    "response_text = response.text\n",
    "\n",
    "events_df = get_upcoming_events(response_text, css_class_dict)\n",
    "events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccac2e9",
   "metadata": {},
   "source": [
    "### Using `urllib3` library\n",
    "This is another common library for retrieving data from URLs and for other functions involving URLs such as parsing of the parts of the actual URL and handling various encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd54148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e82415f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EuroPython 2023</td>\n",
       "      <td>Prague, Czech Republic</td>\n",
       "      <td>17 July – 23 July  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North Bay Python</td>\n",
       "      <td>Petaluma, California, USA</td>\n",
       "      <td>29 July – 30 July  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PyCon PL 2023</td>\n",
       "      <td>Gliwice, Poland</td>\n",
       "      <td>29 July – 02 Aug.  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PyCon KR</td>\n",
       "      <td>Seoul, South Korea</td>\n",
       "      <td>11 Aug. – 13 Aug.  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EuroSciPy 2023</td>\n",
       "      <td>Basel, Switzerland</td>\n",
       "      <td>14 Aug. – 18 Aug.  2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DjangoConAU 2023</td>\n",
       "      <td>Adelaide, Australia</td>\n",
       "      <td>18 Aug. 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                   location                     time\n",
       "0   EuroPython 2023     Prague, Czech Republic  17 July – 23 July  2023\n",
       "1  North Bay Python  Petaluma, California, USA  29 July – 30 July  2023\n",
       "2     PyCon PL 2023            Gliwice, Poland  29 July – 02 Aug.  2023\n",
       "3          PyCon KR         Seoul, South Korea  11 Aug. – 13 Aug.  2023\n",
       "4    EuroSciPy 2023         Basel, Switzerland  14 Aug. – 18 Aug.  2023\n",
       "5  DjangoConAU 2023        Adelaide, Australia             18 Aug. 2023"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# urllib3 doesn't apply header encoding automatically\n",
    "pool_manager = urllib3.PoolManager()\n",
    "\n",
    "# GET HTTP request using urllib3 library\n",
    "response = pool_manager.request('GET', url)\n",
    "response_text = response.data\n",
    "\n",
    "events_df = get_upcoming_events(response_text, css_class_dict)\n",
    "events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c3ed4a",
   "metadata": {},
   "source": [
    "`requests` and `urllib3` are very similar in terms of capabilities. It is generally recommended to use Requests when it comes to making HTTP requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0390f01a",
   "metadata": {},
   "source": [
    "## Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f374c236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate\", \n",
      "    \"Cookie\": \"my-cookie=browser\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.28.1\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-64b46142-593c4af214b336c527d485ba\"\n",
      "  }, \n",
      "  \"origin\": \"165.23.15.159\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# builds on top of urllib3's connection pooling\n",
    "\n",
    "# session reuses the same TCP connection if requests are made to the same host\n",
    "session = requests.Session()\n",
    "\n",
    "r = session.get('http://httpbin.org/get', cookies={'my-cookie': 'browser'})\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e4067",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "776093b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'http://httpbin.org/stream/5', 'args': {}, 'headers': {'Host': 'httpbin.org', 'X-Amzn-Trace-Id': 'Root=1-64b46142-0f4a3eaf4a030b065b0a641c', 'User-Agent': 'python-requests/2.28.1', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*'}, 'origin': '165.23.15.159', 'id': 0}\n",
      "{'url': 'http://httpbin.org/stream/5', 'args': {}, 'headers': {'Host': 'httpbin.org', 'X-Amzn-Trace-Id': 'Root=1-64b46142-0f4a3eaf4a030b065b0a641c', 'User-Agent': 'python-requests/2.28.1', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*'}, 'origin': '165.23.15.159', 'id': 1}\n",
      "{'url': 'http://httpbin.org/stream/5', 'args': {}, 'headers': {'Host': 'httpbin.org', 'X-Amzn-Trace-Id': 'Root=1-64b46142-0f4a3eaf4a030b065b0a641c', 'User-Agent': 'python-requests/2.28.1', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*'}, 'origin': '165.23.15.159', 'id': 2}\n",
      "{'url': 'http://httpbin.org/stream/5', 'args': {}, 'headers': {'Host': 'httpbin.org', 'X-Amzn-Trace-Id': 'Root=1-64b46142-0f4a3eaf4a030b065b0a641c', 'User-Agent': 'python-requests/2.28.1', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*'}, 'origin': '165.23.15.159', 'id': 3}\n",
      "{'url': 'http://httpbin.org/stream/5', 'args': {}, 'headers': {'Host': 'httpbin.org', 'X-Amzn-Trace-Id': 'Root=1-64b46142-0f4a3eaf4a030b065b0a641c', 'User-Agent': 'python-requests/2.28.1', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*'}, 'origin': '165.23.15.159', 'id': 4}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Streaming is another nifty feature\n",
    "r = requests.get('http://httpbin.org/stream/5', stream=True)\n",
    "\n",
    "for line in r.iter_lines():\n",
    "    # filter out keep-alive new lines\n",
    "    if line:\n",
    "        decoded_line = line.decode('utf-8')\n",
    "        print(json.loads(decoded_line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04799b4d",
   "metadata": {},
   "source": [
    "## Scraping with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e28ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def get_upcoming_events_with_Selenium(url):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_argument(\"disable-infobars\")\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.maximize_window()\n",
    "    driver.get(url)\n",
    "    \n",
    "    upcoming_events = []\n",
    "    events = driver.find_elements(\"xpath\",'//ul[contains(@class, \"list-recent-events\")]/li')\n",
    "    for event in events:\n",
    "        event_details = dict()\n",
    "        event_details['name'] = event.find_element(\"xpath\",'h3[@class=\"event-title\"]/a').text\n",
    "        event_details['location'] = event.find_element(\"xpath\",'p/span[@class=\"event-location\"]').text\n",
    "        event_details['time'] = event.find_element(\"xpath\",'p/time').text\n",
    "        upcoming_events.append(event_details)\n",
    "    \n",
    "    driver.close()\n",
    "    events_df = pd.DataFrame(upcoming_events)\n",
    "    return events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6e78517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|████████████████████████████████████████████████████████| 6.30M/6.30M [00:00<00:00, 18.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EuroPython 2023</td>\n",
       "      <td>Prague, Czech Republic</td>\n",
       "      <td>17 July – 23 July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North Bay Python</td>\n",
       "      <td>Petaluma, California, USA</td>\n",
       "      <td>29 July – 30 July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PyCon PL 2023</td>\n",
       "      <td>Gliwice, Poland</td>\n",
       "      <td>29 July – 02 Aug.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PyCon KR</td>\n",
       "      <td>Seoul, South Korea</td>\n",
       "      <td>11 Aug. – 13 Aug.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EuroSciPy 2023</td>\n",
       "      <td>Basel, Switzerland</td>\n",
       "      <td>14 Aug. – 18 Aug.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DjangoConAU 2023</td>\n",
       "      <td>Adelaide, Australia</td>\n",
       "      <td>18 Aug.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SciPy 2023</td>\n",
       "      <td>Austin, Texas, USA</td>\n",
       "      <td>10 July – 16 July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PyCon Israel 2023</td>\n",
       "      <td>Ramat Gan, Israel</td>\n",
       "      <td>04 July – 05 July</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name                   location               time\n",
       "0    EuroPython 2023     Prague, Czech Republic  17 July – 23 July\n",
       "1   North Bay Python  Petaluma, California, USA  29 July – 30 July\n",
       "2      PyCon PL 2023            Gliwice, Poland  29 July – 02 Aug.\n",
       "3           PyCon KR         Seoul, South Korea  11 Aug. – 13 Aug.\n",
       "4     EuroSciPy 2023         Basel, Switzerland  14 Aug. – 18 Aug.\n",
       "5   DjangoConAU 2023        Adelaide, Australia            18 Aug.\n",
       "6         SciPy 2023         Austin, Texas, USA  10 July – 16 July\n",
       "7  PyCon Israel 2023          Ramat Gan, Israel  04 July – 05 July"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = get_upcoming_events_with_Selenium(url)\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5c86c2",
   "metadata": {},
   "source": [
    "## DOM\n",
    "\n",
    "When the browser displays a web page it builds a model of the content of the page in a representation known as the **document object model** (**DOM**). The DOM is a hierarchical representation of the page's entire content, as well as structural information, style information, scripts, and links to other content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6137ee78",
   "metadata": {},
   "source": [
    "# Scrapy Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684050b",
   "metadata": {},
   "source": [
    "Scrapy is a very popular open source Python scraping framework for extracting data. It was originally designed for only scraping, but it is has also evolved into a powerful web crawling solution. Scrapy offers a number of powerful features:\n",
    "\n",
    "* Built-in extensions to make HTTP requests and handle compression, authentication, caching, manipulate user-agents, and HTTP headers\n",
    "\n",
    "* Built-in support for selecting and extracting data with selector languages such as CSS and XPath, as well as support for utilizing regular expressions for selection of content and links\n",
    "\n",
    "* Encoding support to deal with languages and non-standard encoding declarations\n",
    "\n",
    "* Flexible APIs to reuse and write custom middleware and pipelines, which provide a clean and easy way to implement tasks such as automatically downloading assets (for example, images or media) and storing data in storage such as file systems, S3, databases, and others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b6f4b0",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873139f",
   "metadata": {},
   "source": [
    "* https://github.com/PacktPublishing/Python-Web-Scraping-Cookbook/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e89c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
